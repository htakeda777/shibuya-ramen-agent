#!/usr/bin/env python3
"""
æ¸‹è°·åŒºãƒ©ãƒ¼ãƒ¡ãƒ³åº—ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

Claude Agent SDK ã‚’ä½¿ç”¨ã—ã¦æ¸‹è°·åŒºã®ãƒ©ãƒ¼ãƒ¡ãƒ³åº—æƒ…å ±ã‚’ Web ã‹ã‚‰åé›†ã—ã€
JSON å½¢å¼ã§ä¿å­˜ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
"""

import asyncio
import json
import os
from pathlib import Path
from datetime import datetime
from typing import Any

from claude_agent_sdk import query, ClaudeAgentOptions


# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = Path(__file__).parent.parent / "output"

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """ã‚ãªãŸã¯æ¸‹è°·åŒºã®ãƒ©ãƒ¼ãƒ¡ãƒ³åº—æƒ…å ±ã‚’åé›†ã™ã‚‹å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

## ã‚¿ã‚¹ã‚¯
æ¸‹è°·åŒºã«ã‚ã‚‹ãƒ©ãƒ¼ãƒ¡ãƒ³åº—ã®æƒ…å ±ã‚’åé›†ã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

## åé›†ã™ã‚‹æƒ…å ±
å„ãƒ©ãƒ¼ãƒ¡ãƒ³åº—ã«ã¤ã„ã¦ä»¥ä¸‹ã®æƒ…å ±ã‚’åé›†ã—ã¦ãã ã•ã„ï¼š
- name: åº—å
- address: ä½æ‰€
- area: ã‚¨ãƒªã‚¢ï¼ˆæ¸‹è°·ã€æµæ¯”å¯¿ã€ä»£å®˜å±±ã€åŸå®¿ã€è¡¨å‚é“ã€ç¥æ³‰ãªã©ï¼‰
- genre: ãƒ©ãƒ¼ãƒ¡ãƒ³ã®ç¨®é¡ï¼ˆé†¤æ²¹ã€å‘³å™Œã€å¡©ã€è±šéª¨ã€å®¶ç³»ã€äºŒéƒç³»ã€ã¤ã‘éººãªã©ï¼‰
- rating: è©•ä¾¡ï¼ˆ5ç‚¹æº€ç‚¹ã€ä¸æ˜ãªå ´åˆã¯ nullï¼‰
- price_range: ä¾¡æ ¼å¸¯ï¼ˆä¾‹: "800-1200å††"ï¼‰
- specialties: çœ‹æ¿ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚„ç‰¹å¾´ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ï¼‰
- hours: å–¶æ¥­æ™‚é–“
- closed_days: å®šä¼‘æ—¥
- url: å…¬å¼ã‚µã‚¤ãƒˆã¾ãŸã¯æƒ…å ±æºURL
- description: åº—èˆ—ã®èª¬æ˜ã‚„ç‰¹å¾´

## åé›†æ–¹æ³•
1. WebSearch ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€Œæ¸‹è°·åŒº ãƒ©ãƒ¼ãƒ¡ãƒ³ã€ã€Œæ¸‹è°· ãƒ©ãƒ¼ãƒ¡ãƒ³ äººæ°—ã€ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
2. æ¤œç´¢çµæœã‹ã‚‰æœ‰ååº—ã‚„äººæ°—åº—ã‚’ç‰¹å®š
3. WebFetch ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦å„åº—èˆ—ã®è©³ç´°æƒ…å ±ã‚’åé›†
4. æœ€ä½20åº—èˆ—ä»¥ä¸Šã®æƒ…å ±ã‚’åé›†ã™ã‚‹ã“ã¨ã‚’ç›®æ¨™ã¨ã™ã‚‹

## å‡ºåŠ›å½¢å¼
æœ€çµ‚çš„ã«ä»¥ä¸‹ã®JSONå½¢å¼ã§çµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```json
{
  "collected_at": "YYYY-MM-DD HH:MM:SS",
  "total_count": æ•°å€¤,
  "shops": [
    {
      "name": "åº—å",
      "address": "ä½æ‰€",
      "area": "ã‚¨ãƒªã‚¢",
      "genre": "ã‚¸ãƒ£ãƒ³ãƒ«",
      "rating": 4.5,
      "price_range": "800-1200å††",
      "specialties": ["ç‰¹è£½ãƒ©ãƒ¼ãƒ¡ãƒ³", "ãƒãƒ£ãƒ¼ã‚·ãƒ¥ãƒ¼éºº"],
      "hours": "11:00-23:00",
      "closed_days": "æœˆæ›œæ—¥",
      "url": "https://...",
      "description": "èª¬æ˜æ–‡"
    }
  ]
}
```

## é‡è¦ãªæ³¨æ„äº‹é …
- å®Ÿåœ¨ã™ã‚‹åº—èˆ—ã®æƒ…å ±ã®ã¿ã‚’åé›†ã—ã¦ãã ã•ã„
- æƒ…å ±ãŒä¸æ˜ãªå ´åˆã¯ null ã‚’è¨­å®šã—ã¦ãã ã•ã„
- é–‰åº—ã—ãŸåº—èˆ—ã¯å«ã‚ãªã„ã§ãã ã•ã„
- æƒ…å ±æºã‚’æ˜è¨˜ã—ã¦ãã ã•ã„

æœ€å¾Œã«ã€åé›†ã—ãŸå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šè¨˜ã® JSON å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
JSON ã¯ ```json ã¨ ``` ã§å›²ã‚“ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""


async def collect_ramen_data() -> dict[str, Any]:
    """
    æ¸‹è°·åŒºã®ãƒ©ãƒ¼ãƒ¡ãƒ³åº—ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
    """
    print("=" * 60)
    print("ğŸœ æ¸‹è°·åŒºãƒ©ãƒ¼ãƒ¡ãƒ³åº—ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    print("=" * 60)
    print()

    options = ClaudeAgentOptions(
        system_prompt=SYSTEM_PROMPT,
        allowed_tools=["WebSearch", "WebFetch"],
        permission_mode='acceptEdits',
        max_turns=50,  # ååˆ†ãªæ¢ç´¢ã‚’è¨±å¯
    )

    collected_text = ""

    print("ğŸ“¡ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
    print("-" * 60)

    async for message in query(
        prompt="""æ¸‹è°·åŒºã®ãƒ©ãƒ¼ãƒ¡ãƒ³åº—æƒ…å ±ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®æ‰‹é †ã§é€²ã‚ã¦ãã ã•ã„ï¼š
1. ã¾ãšã€Œæ¸‹è°·åŒº ãƒ©ãƒ¼ãƒ¡ãƒ³ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ã€Œæ¸‹è°· ãƒ©ãƒ¼ãƒ¡ãƒ³ äººæ°—ã€ã§æ¤œç´¢ã—ã¦æœ‰ååº—ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
2. å„ã‚¨ãƒªã‚¢ï¼ˆæ¸‹è°·ã€æµæ¯”å¯¿ã€ä»£å®˜å±±ã€åŸå®¿ã€è¡¨å‚é“ï¼‰ã”ã¨ã«ã‚‚æ¤œç´¢
3. è¦‹ã¤ã‹ã£ãŸåº—èˆ—ã®è©³ç´°æƒ…å ±ã‚’ WebFetch ã§åé›†
4. æœ€çµ‚çš„ã« JSON å½¢å¼ã§å‡ºåŠ›

ã§ãã‚‹ã ã‘å¤šãã®åº—èˆ—æƒ…å ±ï¼ˆ20åº—èˆ—ä»¥ä¸Šï¼‰ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚""",
        options=options
    ):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
        if hasattr(message, 'content'):
            for block in message.content:
                if hasattr(block, 'text'):
                    text = block.text
                    print(text)
                    collected_text += text + "\n"
                elif hasattr(block, 'name'):
                    # ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®è¡¨ç¤º
                    print(f"\nğŸ”§ Tool: {block.name}")
        elif hasattr(message, 'type') and message.type == 'result':
            # ãƒ„ãƒ¼ãƒ«çµæœï¼ˆç°¡ç•¥è¡¨ç¤ºï¼‰
            if hasattr(message, 'content'):
                result_preview = str(message.content)[:200]
                print(f"   â†³ {result_preview}...")

    print("-" * 60)
    print("âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
    print()

    # JSON ã‚’æŠ½å‡º
    ramen_data = extract_json_from_text(collected_text)

    return ramen_data


def extract_json_from_text(text: str) -> dict[str, Any]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ JSON ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    """
    import re

    # ```json ... ``` ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
    json_pattern = r'```json\s*([\s\S]*?)\s*```'
    matches = re.findall(json_pattern, text)

    if matches:
        # æœ€å¾Œã® JSON ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼ˆæœ€çµ‚çµæœã®ã¯ãšï¼‰
        try:
            return json.loads(matches[-1])
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼š{...} ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
    brace_pattern = r'\{[\s\S]*"shops"[\s\S]*\}'
    brace_matches = re.findall(brace_pattern, text)

    if brace_matches:
        for match in reversed(brace_matches):
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue

    # ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç©ºã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™
    return {
        "collected_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_count": 0,
        "shops": [],
        "error": "JSON ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"
    }


def save_data(data: dict[str, Any], filename: str = "ramen_shops.json") -> Path:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    """
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    filepath = OUTPUT_DIR / filename

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
    return filepath


async def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    try:
        # ãƒ‡ãƒ¼ã‚¿åé›†
        ramen_data = await collect_ramen_data()

        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        save_data(ramen_data)

        # çµ±è¨ˆè¡¨ç¤º
        print()
        print("=" * 60)
        print("ğŸ“Š åé›†çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        print(f"åé›†æ—¥æ™‚: {ramen_data.get('collected_at', 'N/A')}")
        print(f"åº—èˆ—æ•°: {ramen_data.get('total_count', len(ramen_data.get('shops', [])))}")

        if ramen_data.get('shops'):
            # ã‚¨ãƒªã‚¢åˆ¥é›†è¨ˆ
            areas = {}
            genres = {}
            for shop in ramen_data['shops']:
                area = shop.get('area', 'ä¸æ˜')
                genre = shop.get('genre', 'ä¸æ˜')
                areas[area] = areas.get(area, 0) + 1
                genres[genre] = genres.get(genre, 0) + 1

            print("\nğŸ—ºï¸ ã‚¨ãƒªã‚¢åˆ¥:")
            for area, count in sorted(areas.items(), key=lambda x: -x[1]):
                print(f"   {area}: {count}åº—")

            print("\nğŸœ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥:")
            for genre, count in sorted(genres.items(), key=lambda x: -x[1]):
                print(f"   {genre}: {count}åº—")

        print()

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
